{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>78</td><td>application_1529092902068_0082</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://thdpcl2nn2.catmktg.com:8088/proxy/application_1529092902068_0082/\">Link</a></td><td><a target=\"_blank\" href=\"http://thdpcl2dn03.catmktg.com:8042/node/containerlogs/container_e117_1529092902068_0082_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "res1: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@122f19d0"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        databaseName|\n",
      "+--------------------+\n",
      "|sample_data...|\n",
      "|             default|\n",
      "|     tpcds_text_1000|\n",
      "+--------------------+"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.SQLContext\n",
    "\n",
    "val sqlContext = new SQLContext(sc)\n",
    "sqlContext.sql(\"Show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+--------+\n",
      "|  name|age|personid|\n",
      "+------+---+--------+\n",
      "| Bindu| 20|       2|\n",
      "|Raphel| 25|       5|\n",
      "|      |  5|       6|\n",
      "|Raphel| 25|       5|\n",
      "|   Ram| 40|       9|\n",
      "+------+---+--------+"
     ]
    }
   ],
   "source": [
    "case class Person(name: String, age: Int, personid: Int)\n",
    "\n",
    "case class Profile(name: String, personid: Int , profileDescription: String)\n",
    "\n",
    "val df1 = sqlContext.createDataFrame(\n",
    "    Person(\"Bindu\",20,  2) \n",
    "    :: Person(\"Raphel\",25, 5) \n",
    "    :: Person(\"\",5, 6) \n",
    "    :: Person(\"Raphel\",25, 5) \n",
    "    :: Person(\"Ram\",40, 9):: Nil)\n",
    "\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res32: Long = 4"
     ]
    }
   ],
   "source": [
    "df1.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- personid: integer (nullable = false)"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  name|\n",
      "+------+\n",
      "| Bindu|\n",
      "|Raphel|\n",
      "|      |\n",
      "|Raphel|\n",
      "|   Ram|\n",
      "+------+"
     ]
    }
   ],
   "source": [
    "df1.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------+\n",
      "|name|age|personid|\n",
      "+----+---+--------+\n",
      "|    |  5|       6|\n",
      "+----+---+--------+"
     ]
    }
   ],
   "source": [
    "df1.filter($\"name\" === \"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------+\n",
      "|name|age|personid|\n",
      "+----+---+--------+\n",
      "+----+---+--------+"
     ]
    }
   ],
   "source": [
    "df1.filter($\"name\" === null).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------+\n",
      "|name|age|personid|\n",
      "+----+---+--------+\n",
      "|    |  5|       6|\n",
      "+----+---+--------+"
     ]
    }
   ],
   "source": [
    "df1.filter($\"name\" <=> \"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+\n",
      "| name|personid|profileDescription|\n",
      "+-----+--------+------------------+\n",
      "|  Ram|       9|    SparkSQLMaster|\n",
      "|Bindu|       2|         SparkGuru|\n",
      "|Spark|       5|         DevHunter|\n",
      "+-----+--------+------------------+"
     ]
    }
   ],
   "source": [
    "val df2 = sqlContext.createDataFrame(\n",
    "    Profile(\"Ram\",9,  \"SparkSQLMaster\") \n",
    "    :: Profile(\"Bindu\",2, \"SparkGuru\") \n",
    "    :: Profile(\"Spark\",5, \"DevHunter\"):: Nil\n",
    ")\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultDf: org.apache.spark.sql.DataFrame = [name: string, personid: int ... 2 more fields]"
     ]
    }
   ],
   "source": [
    "val resultDf = df1.join(df2,Seq(\"name\",\"personId\"), \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+---+------------------+\n",
      "| name|personid|age|profileDescription|\n",
      "+-----+--------+---+------------------+\n",
      "|Bindu|       2| 20|         SparkGuru|\n",
      "|  Ram|       9| 40|    SparkSQLMaster|\n",
      "+-----+--------+---+------------------+"
     ]
    }
   ],
   "source": [
    "resultDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
